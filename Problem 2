import psutil 
import logging
from datetime import datetime

# Configure logging
logging.basicConfig(filename='system_health.log', level=logging.INFO)

# Thresholds
CPU_THRESHOLD = 80
MEMORY_THRESHOLD = 80
DISK_THRESHOLD = 80
PROCESS_THRESHOLD = 300

def log_message(message):
    logging.info(f"{datetime.now()} - {message}")

def check_cpu_usage():
    cpu_usage = psutil.cpu_percent(interval=1)
    if cpu_usage > CPU_THRESHOLD:
        log_message(f"High CPU usage detected: {cpu_usage}%")

def check_memory_usage():
    memory_info = psutil.virtual_memory()
    if memory_info.percent > MEMORY_THRESHOLD:
        log_message(f"High memory usage detected: {memory_info.percent}%")

def check_disk_space():
    disk_info = psutil.disk_usage('/')
    if disk_info.percent > DISK_THRESHOLD:
        log_message(f"Low disk space detected: {disk_info.percent}% used")

def check_running_processes():
    process_count = len(psutil.pids())
    if process_count > PROCESS_THRESHOLD:
        log_message(f"High number of running processes detected: {process_count}")

def monitor_system_health():
    check_cpu_usage()
    check_memory_usage()
    check_disk_space()
    check_running_processes()

if __name__ == "__main__":
    monitor_system_health()
import re
from collections import defaultdict

# Path to the log file
LOG_FILE_PATH = 'access.log'

# Regular expression to parse log lines
log_pattern = re.compile(r'(?P<ip>\S+) \S+ \S+ \[\S+ \S+\] "(?P<method>\S+) (?P<url>\S+) \S+" (?P<status>\d+) \S+')

def analyze_log_file(file_path):
    ip_requests = defaultdict(int)
    url_requests = defaultdict(int)
    status_count = defaultdict(int)
    not_found_count = 0

    with open(file_path, 'r') as file:
        for line in file:
            match = log_pattern.match(line)
            if match:
                ip = match.group('ip')
                url = match.group('url')
                status = match.group('status')

                ip_requests[ip] += 1
                url_requests[url] += 1
                status_count[status] += 1

                if status == '404':
                    not_found_count += 1

    print("Summary Report:")
    print(f"Total 404 Errors: {not_found_count}")
    print("Top 10 Requested Pages:")
    for url, count in sorted(url_requests.items(), key=lambda item: item[1], reverse=True)[:10]:
        print(f"{url}: {count} requests")
    print("Top 10 IP Addresses by Request Count:")
    for ip, count in sorted(ip_requests.items(), key=lambda item: item[1], reverse=True)[:10]:
        print(f"{ip}: {count} requests")

if __name__ == "__main__":
    analyze_log_file(LOG_FILE_PATH)
